# Base model (non-chat) evaluation config
# base_model_name: "Gensyn/Qwen2.5-0.5B-Instruct"
base_model_name: "Qwen/Qwen3-0.6B"
is_chat_model: true

batch_size: 8
max_new_tokens: 256
temperature: 0.7

datasets:
  openai/gsm8k.main:
    enabled: true
    split: "test[:]"
    max_new_tokens: 1024
  
  stanfordnlp/snli:
    enabled: true
    split: "test[:]"
    max_new_tokens: 10
  
  google/boolq:
    enabled: true
    split: "validation[:]"
    max_new_tokens: 10

  allenai/ai2_arc.ARC-Easy:
    enabled: true
    split: "test[:]"
    max_new_tokens: 10

output_path: "results/{model_name}/{timestamp}.json"
