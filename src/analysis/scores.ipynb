{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b907c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b6996b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'EleutherAI/pythia-70m',\n",
    "    'google/gemma-3-270m-it',\n",
    "    'Qwen/Qwen3-0.6B'\n",
    "]\n",
    "\n",
    "zero_shot_datasets = [\n",
    "    'ChilleD/SVAMP',\n",
    "    'tau/commonsense_qa',\n",
    "    'ehovy/race.middle'\n",
    "]\n",
    "\n",
    "dataset_names = {\n",
    "    'allenai/ai2_arc.ARC-Challenge': 'ARC Challenge',\n",
    "    'allenai/ai2_arc.ARC-Easy': 'ARC Easy',\n",
    "    'allenai/openbookqa.main': 'OpenBookQA',\n",
    "    'allenai/winogrande.winogrande_m': 'Winogrande (M)',\n",
    "    'ChilleD/SVAMP': 'SVAMP',\n",
    "    'ehovy/race.middle': 'RACE (Middle)',\n",
    "    'google/boolq': 'BoolQ',\n",
    "    'openai/gsm8k.main': \"GMS8K\",\n",
    "    'Rowan/hellaswag': \"HELLASWAG\",\n",
    "    'stanfordnlp/snli': \"SNLI\",\n",
    "    \"tau/commonsense_qa\": \"CommonSenseQA\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd218b",
   "metadata": {},
   "source": [
    "## Base model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde1942e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARC Challenge</th>\n",
       "      <th>ARC Easy</th>\n",
       "      <th>BoolQ</th>\n",
       "      <th>GMS8K</th>\n",
       "      <th>HELLASWAG</th>\n",
       "      <th>OpenBookQA</th>\n",
       "      <th>SNLI</th>\n",
       "      <th>Winogrande (M)</th>\n",
       "      <th>SVAMP</th>\n",
       "      <th>CommonSenseQA</th>\n",
       "      <th>RACE (Middle)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EleutherAI/pythia-70m</th>\n",
       "      <td>9.13%</td>\n",
       "      <td>7.07%</td>\n",
       "      <td>14.2%</td>\n",
       "      <td>1.29%</td>\n",
       "      <td>4.94%</td>\n",
       "      <td>8.2%</td>\n",
       "      <td>0.519%</td>\n",
       "      <td>6.08%</td>\n",
       "      <td>2.33%</td>\n",
       "      <td>3.44%</td>\n",
       "      <td>8.64%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemma-3-270m-it</th>\n",
       "      <td>18.9%</td>\n",
       "      <td>23.0%</td>\n",
       "      <td>43.5%</td>\n",
       "      <td>4.55%</td>\n",
       "      <td>24.7%</td>\n",
       "      <td>24.6%</td>\n",
       "      <td>34.3%</td>\n",
       "      <td>50.6%</td>\n",
       "      <td>19.3%</td>\n",
       "      <td>18.4%</td>\n",
       "      <td>20.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen/Qwen3-0.6B</th>\n",
       "      <td>21.7%</td>\n",
       "      <td>31.7%</td>\n",
       "      <td>63.6%</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>25.9%</td>\n",
       "      <td>34.2%</td>\n",
       "      <td>42.4%</td>\n",
       "      <td>50.4%</td>\n",
       "      <td>73.0%</td>\n",
       "      <td>38.2%</td>\n",
       "      <td>34.4%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ARC Challenge ARC Easy  BoolQ  GMS8K HELLASWAG  \\\n",
       "EleutherAI/pythia-70m          9.13%    7.07%  14.2%  1.29%     4.94%   \n",
       "google/gemma-3-270m-it         18.9%    23.0%  43.5%  4.55%     24.7%   \n",
       "Qwen/Qwen3-0.6B                21.7%    31.7%  63.6%  50.0%     25.9%   \n",
       "\n",
       "                       OpenBookQA    SNLI Winogrande (M)  SVAMP CommonSenseQA  \\\n",
       "EleutherAI/pythia-70m        8.2%  0.519%          6.08%  2.33%         3.44%   \n",
       "google/gemma-3-270m-it      24.6%   34.3%          50.6%  19.3%         18.4%   \n",
       "Qwen/Qwen3-0.6B             34.2%   42.4%          50.4%  73.0%         38.2%   \n",
       "\n",
       "                       RACE (Middle)  \n",
       "EleutherAI/pythia-70m          8.64%  \n",
       "google/gemma-3-270m-it         20.8%  \n",
       "Qwen/Qwen3-0.6B                34.4%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_path = '../_results/base'\n",
    "\n",
    "raw_base_scores = {}\n",
    "for model in models:\n",
    "    raw_base_scores[model] = {}\n",
    "    summary_path = os.path.join(base_path, model.replace('/', '_'), '_summary.*.json')\n",
    "    summary_files = glob.glob(summary_path)\n",
    "    for summary_file in summary_files:\n",
    "        summary_content = json.load(open(summary_file, 'r'))\n",
    "        raw_base_scores[model].update(summary_content['task_accuracies'])\n",
    "\n",
    "base_scores = {}\n",
    "for model in models:\n",
    "    base_scores[model] = {}\n",
    "    zero_shot_scores = {}\n",
    "    for dataset, score in sorted(raw_base_scores[model].items(), key=lambda x: x[0].split('/')[1]):\n",
    "        dataset_name = dataset_names[dataset]\n",
    "        score = f\"{score * 100:.3}%\"\n",
    "        if dataset in zero_shot_datasets:\n",
    "            zero_shot_scores[dataset_name] = score        \n",
    "        else:\n",
    "            base_scores[model][dataset_name] = score\n",
    "    base_scores[model] = dict(**base_scores[model], **zero_shot_scores)\n",
    "        \n",
    "\n",
    "base_scores_df = pd.DataFrame.from_dict(base_scores, orient='index')\n",
    "display(base_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd65eb6",
   "metadata": {},
   "source": [
    "## Individual LoRA Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d440e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARC Challenge</th>\n",
       "      <th>ARC Easy</th>\n",
       "      <th>BoolQ</th>\n",
       "      <th>GMS8K</th>\n",
       "      <th>HELLASWAG</th>\n",
       "      <th>OpenBookQA</th>\n",
       "      <th>SNLI</th>\n",
       "      <th>Winogrande (M)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EleutherAI/pythia-70m</th>\n",
       "      <td>22.8%</td>\n",
       "      <td>23.7%</td>\n",
       "      <td>53.5%</td>\n",
       "      <td>1.14%</td>\n",
       "      <td>25.4%</td>\n",
       "      <td>22.4%</td>\n",
       "      <td>34.9%</td>\n",
       "      <td>49.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemma-3-270m-it</th>\n",
       "      <td>25.6%</td>\n",
       "      <td>25.0%</td>\n",
       "      <td>56.4%</td>\n",
       "      <td>3.64%</td>\n",
       "      <td>24.2%</td>\n",
       "      <td>26.4%</td>\n",
       "      <td>42.9%</td>\n",
       "      <td>53.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen/Qwen3-0.6B</th>\n",
       "      <td>50.7%</td>\n",
       "      <td>71.8%</td>\n",
       "      <td>78.8%</td>\n",
       "      <td>35.9%</td>\n",
       "      <td>50.7%</td>\n",
       "      <td>62.2%</td>\n",
       "      <td>84.2%</td>\n",
       "      <td>48.7%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ARC Challenge ARC Easy  BoolQ  GMS8K HELLASWAG  \\\n",
       "EleutherAI/pythia-70m          22.8%    23.7%  53.5%  1.14%     25.4%   \n",
       "google/gemma-3-270m-it         25.6%    25.0%  56.4%  3.64%     24.2%   \n",
       "Qwen/Qwen3-0.6B                50.7%    71.8%  78.8%  35.9%     50.7%   \n",
       "\n",
       "                       OpenBookQA   SNLI Winogrande (M)  \n",
       "EleutherAI/pythia-70m       22.4%  34.9%          49.7%  \n",
       "google/gemma-3-270m-it      26.4%  42.9%          53.8%  \n",
       "Qwen/Qwen3-0.6B             62.2%  84.2%          48.7%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lora_base_path = '../_results/lora'\n",
    "\n",
    "raw_lora_scores = {}\n",
    "for model in models:\n",
    "    raw_lora_scores[model] = {}\n",
    "    model_path = os.path.join(lora_base_path, model.replace('/', '_'), '*')\n",
    "    lora_paths = [path for path in glob.glob(model_path) if not path.endswith('mix_8')]\n",
    "    \n",
    "    for lora_path in lora_paths:\n",
    "        results_file = glob.glob(os.path.join(lora_path, '*.results.*.json'))[0]\n",
    "        results_data = json.load(open(results_file, 'r'))\n",
    "        dataset = results_data['task']\n",
    "        score = results_data['metrics']['accuracy']\n",
    "        raw_lora_scores[model][dataset] = score\n",
    "\n",
    "lora_scores = {}\n",
    "for model in models:\n",
    "    lora_scores[model] = {}\n",
    "    zero_shot_scores = {}\n",
    "    for dataset, score in sorted(raw_lora_scores[model].items(), key=lambda x: x[0].split('/')[1]):\n",
    "        dataset_name = dataset_names[dataset]\n",
    "        score = f\"{score * 100:.3}%\"\n",
    "        if dataset in zero_shot_datasets:\n",
    "            zero_shot_scores[dataset_name] = score        \n",
    "        else:\n",
    "            lora_scores[model][dataset_name] = score\n",
    "    lora_scores[model] = dict(**lora_scores[model], **zero_shot_scores)\n",
    "\n",
    "lora_scores_df = pd.DataFrame.from_dict(lora_scores, orient='index')\n",
    "display(lora_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a45dd5",
   "metadata": {},
   "source": [
    "## Mixed LoRA Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e00d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARC Challenge</th>\n",
       "      <th>ARC Easy</th>\n",
       "      <th>BoolQ</th>\n",
       "      <th>GMS8K</th>\n",
       "      <th>HELLASWAG</th>\n",
       "      <th>OpenBookQA</th>\n",
       "      <th>SNLI</th>\n",
       "      <th>Winogrande (M)</th>\n",
       "      <th>SVAMP</th>\n",
       "      <th>CommonSenseQA</th>\n",
       "      <th>RACE (Middle)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EleutherAI/pythia-70m</th>\n",
       "      <td>24.1%</td>\n",
       "      <td>22.3%</td>\n",
       "      <td>53.9%</td>\n",
       "      <td>1.97%</td>\n",
       "      <td>24.6%</td>\n",
       "      <td>26.6%</td>\n",
       "      <td>31.0%</td>\n",
       "      <td>44.3%</td>\n",
       "      <td>3.0%</td>\n",
       "      <td>18.3%</td>\n",
       "      <td>18.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemma-3-270m-it</th>\n",
       "      <td>25.3%</td>\n",
       "      <td>21.3%</td>\n",
       "      <td>52.0%</td>\n",
       "      <td>3.41%</td>\n",
       "      <td>23.5%</td>\n",
       "      <td>25.2%</td>\n",
       "      <td>33.3%</td>\n",
       "      <td>50.9%</td>\n",
       "      <td>4.67%</td>\n",
       "      <td>20.6%</td>\n",
       "      <td>22.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen/Qwen3-0.6B</th>\n",
       "      <td>54.4%</td>\n",
       "      <td>68.8%</td>\n",
       "      <td>68.6%</td>\n",
       "      <td>34.5%</td>\n",
       "      <td>33.0%</td>\n",
       "      <td>53.4%</td>\n",
       "      <td>76.9%</td>\n",
       "      <td>48.5%</td>\n",
       "      <td>52.7%</td>\n",
       "      <td>50.9%</td>\n",
       "      <td>64.8%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ARC Challenge ARC Easy  BoolQ  GMS8K HELLASWAG  \\\n",
       "EleutherAI/pythia-70m          24.1%    22.3%  53.9%  1.97%     24.6%   \n",
       "google/gemma-3-270m-it         25.3%    21.3%  52.0%  3.41%     23.5%   \n",
       "Qwen/Qwen3-0.6B                54.4%    68.8%  68.6%  34.5%     33.0%   \n",
       "\n",
       "                       OpenBookQA   SNLI Winogrande (M)  SVAMP CommonSenseQA  \\\n",
       "EleutherAI/pythia-70m       26.6%  31.0%          44.3%   3.0%         18.3%   \n",
       "google/gemma-3-270m-it      25.2%  33.3%          50.9%  4.67%         20.6%   \n",
       "Qwen/Qwen3-0.6B             53.4%  76.9%          48.5%  52.7%         50.9%   \n",
       "\n",
       "                       RACE (Middle)  \n",
       "EleutherAI/pythia-70m          18.7%  \n",
       "google/gemma-3-270m-it         22.8%  \n",
       "Qwen/Qwen3-0.6B                64.8%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lora_base_path = '../_results/lora'\n",
    "\n",
    "raw_mixed_lora_scores = {}\n",
    "for model in models:\n",
    "    raw_mixed_lora_scores[model] = {}\n",
    "    summary_path = os.path.join(lora_base_path, model.replace('/','_'), 'mix_8', '*_summary.*.json')\n",
    "    summary_files = glob.glob(summary_path)\n",
    "    \n",
    "    for summary_file in summary_files:\n",
    "        summary_content = json.load(open(summary_file, 'r'))\n",
    "        raw_mixed_lora_scores[model].update(summary_content['task_accuracies'])\n",
    "\n",
    "mixed_lora_scores = {}\n",
    "for model in models:\n",
    "    mixed_lora_scores[model] = {}\n",
    "    zero_shot_scores = {}\n",
    "    for dataset, score in sorted(raw_mixed_lora_scores[model].items(), key=lambda x: x[0].split('/')[1]):\n",
    "        dataset_name = dataset_names[dataset]\n",
    "        score = f\"{score * 100:.3}%\"\n",
    "        if dataset in zero_shot_datasets:\n",
    "            zero_shot_scores[dataset_name] = score        \n",
    "        else:\n",
    "            mixed_lora_scores[model][dataset_name] = score\n",
    "    mixed_lora_scores[model] = dict(**mixed_lora_scores[model], **zero_shot_scores)\n",
    "\n",
    "mixed_lora_scores_df = pd.DataFrame.from_dict(mixed_lora_scores, orient='index')\n",
    "display(mixed_lora_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b5378",
   "metadata": {},
   "source": [
    "## Hypernet Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "533dcdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARC Challenge</th>\n",
       "      <th>ARC Easy</th>\n",
       "      <th>BoolQ</th>\n",
       "      <th>GMS8K</th>\n",
       "      <th>HELLASWAG</th>\n",
       "      <th>OpenBookQA</th>\n",
       "      <th>SNLI</th>\n",
       "      <th>Winogrande (M)</th>\n",
       "      <th>SVAMP</th>\n",
       "      <th>CommonSenseQA</th>\n",
       "      <th>RACE (Middle)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EleutherAI/pythia-70m</th>\n",
       "      <td>24.9%</td>\n",
       "      <td>23.9%</td>\n",
       "      <td>54.5%</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>24.8%</td>\n",
       "      <td>28.6%</td>\n",
       "      <td>29.5%</td>\n",
       "      <td>48.4%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>19.7%</td>\n",
       "      <td>25.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemma-3-270m-it</th>\n",
       "      <td>21.1%</td>\n",
       "      <td>23.7%</td>\n",
       "      <td>45.7%</td>\n",
       "      <td>5.84%</td>\n",
       "      <td>24.5%</td>\n",
       "      <td>27.6%</td>\n",
       "      <td>34.7%</td>\n",
       "      <td>47.8%</td>\n",
       "      <td>16.3%</td>\n",
       "      <td>21.5%</td>\n",
       "      <td>23.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen/Qwen3-0.6B</th>\n",
       "      <td>35.2%</td>\n",
       "      <td>48.5%</td>\n",
       "      <td>64.1%</td>\n",
       "      <td>52.5%</td>\n",
       "      <td>29.0%</td>\n",
       "      <td>38.8%</td>\n",
       "      <td>49.2%</td>\n",
       "      <td>52.1%</td>\n",
       "      <td>74.7%</td>\n",
       "      <td>45.9%</td>\n",
       "      <td>44.2%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ARC Challenge ARC Easy  BoolQ  GMS8K HELLASWAG  \\\n",
       "EleutherAI/pythia-70m          24.9%    23.9%  54.5%  1.67%     24.8%   \n",
       "google/gemma-3-270m-it         21.1%    23.7%  45.7%  5.84%     24.5%   \n",
       "Qwen/Qwen3-0.6B                35.2%    48.5%  64.1%  52.5%     29.0%   \n",
       "\n",
       "                       OpenBookQA   SNLI Winogrande (M)  SVAMP CommonSenseQA  \\\n",
       "EleutherAI/pythia-70m       28.6%  29.5%          48.4%   1.0%         19.7%   \n",
       "google/gemma-3-270m-it      27.6%  34.7%          47.8%  16.3%         21.5%   \n",
       "Qwen/Qwen3-0.6B             38.8%  49.2%          52.1%  74.7%         45.9%   \n",
       "\n",
       "                       RACE (Middle)  \n",
       "EleutherAI/pythia-70m          25.1%  \n",
       "google/gemma-3-270m-it         23.0%  \n",
       "Qwen/Qwen3-0.6B                44.2%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hypernet_base_path = '../_results/hypernet'\n",
    "\n",
    "raw_hypernet_scores = {}\n",
    "\n",
    "for model in models:\n",
    "    raw_hypernet_scores[model] = {}\n",
    "    summary_path = os.path.join(hypernet_base_path, model.replace('/', '_'), 'mix_8_d1024_r2_a8', '*_summary.*.json')\n",
    "    summary_files = glob.glob(summary_path)\n",
    "\n",
    "    for summary_file in summary_files:\n",
    "        summary_content = json.load(open(summary_file, 'r'))\n",
    "        raw_hypernet_scores[model].update(summary_content['task_accuracies'])\n",
    "\n",
    "hypernet_scores = {}\n",
    "for model in models:\n",
    "    hypernet_scores[model] = {}\n",
    "    zero_shot_scores = {}\n",
    "    for dataset, score in sorted(raw_hypernet_scores[model].items(), key=lambda x: x[0].split('/')[1]):\n",
    "        dataset_name = dataset_names[dataset]\n",
    "        score = f\"{score * 100:.3}%\"\n",
    "        if dataset in zero_shot_datasets:\n",
    "            zero_shot_scores[dataset_name] = score        \n",
    "        else:\n",
    "            hypernet_scores[model][dataset_name] = score\n",
    "    hypernet_scores[model] = dict(**hypernet_scores[model], **zero_shot_scores)\n",
    "\n",
    "hypernet_scores_df = pd.DataFrame.from_dict(hypernet_scores, orient='index')\n",
    "display(hypernet_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d7bde",
   "metadata": {},
   "source": [
    "## Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6926dba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ARC Challenge</th>\n",
       "      <th>ARC Easy</th>\n",
       "      <th>BoolQ</th>\n",
       "      <th>GMS8K</th>\n",
       "      <th>HELLASWAG</th>\n",
       "      <th>OpenBookQA</th>\n",
       "      <th>SNLI</th>\n",
       "      <th>Winogrande (M)</th>\n",
       "      <th>SVAMP</th>\n",
       "      <th>CommonSenseQA</th>\n",
       "      <th>RACE (Middle)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Mode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">EleutherAI/pythia-70m</th>\n",
       "      <th>Base</th>\n",
       "      <td>9.13%</td>\n",
       "      <td>7.07%</td>\n",
       "      <td>14.2%</td>\n",
       "      <td>1.29%</td>\n",
       "      <td>4.94%</td>\n",
       "      <td>8.2%</td>\n",
       "      <td>0.519%</td>\n",
       "      <td>6.08%</td>\n",
       "      <td>2.33%</td>\n",
       "      <td>3.44%</td>\n",
       "      <td>8.64%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA (Individual)</th>\n",
       "      <td>22.8%</td>\n",
       "      <td>23.7%</td>\n",
       "      <td>53.5%</td>\n",
       "      <td>1.14%</td>\n",
       "      <td>25.4%</td>\n",
       "      <td>22.4%</td>\n",
       "      <td>34.9%</td>\n",
       "      <td>49.7%</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA (Mixed)</th>\n",
       "      <td>24.1%</td>\n",
       "      <td>22.3%</td>\n",
       "      <td>53.9%</td>\n",
       "      <td>1.97%</td>\n",
       "      <td>24.6%</td>\n",
       "      <td>26.6%</td>\n",
       "      <td>31.0%</td>\n",
       "      <td>44.3%</td>\n",
       "      <td>3.0%</td>\n",
       "      <td>18.3%</td>\n",
       "      <td>18.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TaskWeaver (Ours)</th>\n",
       "      <td>24.9%</td>\n",
       "      <td>23.9%</td>\n",
       "      <td>54.5%</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>24.8%</td>\n",
       "      <td>28.6%</td>\n",
       "      <td>29.5%</td>\n",
       "      <td>48.4%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>19.7%</td>\n",
       "      <td>25.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">google/gemma-3-270m-it</th>\n",
       "      <th>Base</th>\n",
       "      <td>18.9%</td>\n",
       "      <td>23.0%</td>\n",
       "      <td>43.5%</td>\n",
       "      <td>4.55%</td>\n",
       "      <td>24.7%</td>\n",
       "      <td>24.6%</td>\n",
       "      <td>34.3%</td>\n",
       "      <td>50.6%</td>\n",
       "      <td>19.3%</td>\n",
       "      <td>18.4%</td>\n",
       "      <td>20.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA (Individual)</th>\n",
       "      <td>25.6%</td>\n",
       "      <td>25.0%</td>\n",
       "      <td>56.4%</td>\n",
       "      <td>3.64%</td>\n",
       "      <td>24.2%</td>\n",
       "      <td>26.4%</td>\n",
       "      <td>42.9%</td>\n",
       "      <td>53.8%</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA (Mixed)</th>\n",
       "      <td>25.3%</td>\n",
       "      <td>21.3%</td>\n",
       "      <td>52.0%</td>\n",
       "      <td>3.41%</td>\n",
       "      <td>23.5%</td>\n",
       "      <td>25.2%</td>\n",
       "      <td>33.3%</td>\n",
       "      <td>50.9%</td>\n",
       "      <td>4.67%</td>\n",
       "      <td>20.6%</td>\n",
       "      <td>22.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TaskWeaver (Ours)</th>\n",
       "      <td>21.1%</td>\n",
       "      <td>23.7%</td>\n",
       "      <td>45.7%</td>\n",
       "      <td>5.84%</td>\n",
       "      <td>24.5%</td>\n",
       "      <td>27.6%</td>\n",
       "      <td>34.7%</td>\n",
       "      <td>47.8%</td>\n",
       "      <td>16.3%</td>\n",
       "      <td>21.5%</td>\n",
       "      <td>23.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Qwen/Qwen3-0.6B</th>\n",
       "      <th>Base</th>\n",
       "      <td>21.7%</td>\n",
       "      <td>31.7%</td>\n",
       "      <td>63.6%</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>25.9%</td>\n",
       "      <td>34.2%</td>\n",
       "      <td>42.4%</td>\n",
       "      <td>50.4%</td>\n",
       "      <td>73.0%</td>\n",
       "      <td>38.2%</td>\n",
       "      <td>34.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA (Individual)</th>\n",
       "      <td>50.7%</td>\n",
       "      <td>71.8%</td>\n",
       "      <td>78.8%</td>\n",
       "      <td>35.9%</td>\n",
       "      <td>50.7%</td>\n",
       "      <td>62.2%</td>\n",
       "      <td>84.2%</td>\n",
       "      <td>48.7%</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA (Mixed)</th>\n",
       "      <td>54.4%</td>\n",
       "      <td>68.8%</td>\n",
       "      <td>68.6%</td>\n",
       "      <td>34.5%</td>\n",
       "      <td>33.0%</td>\n",
       "      <td>53.4%</td>\n",
       "      <td>76.9%</td>\n",
       "      <td>48.5%</td>\n",
       "      <td>52.7%</td>\n",
       "      <td>50.9%</td>\n",
       "      <td>64.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TaskWeaver (Ours)</th>\n",
       "      <td>35.2%</td>\n",
       "      <td>48.5%</td>\n",
       "      <td>64.1%</td>\n",
       "      <td>52.5%</td>\n",
       "      <td>29.0%</td>\n",
       "      <td>38.8%</td>\n",
       "      <td>49.2%</td>\n",
       "      <td>52.1%</td>\n",
       "      <td>74.7%</td>\n",
       "      <td>45.9%</td>\n",
       "      <td>44.2%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ARC Challenge ARC Easy  BoolQ  GMS8K  \\\n",
       "Model                  Mode                                                     \n",
       "EleutherAI/pythia-70m  Base                      9.13%    7.07%  14.2%  1.29%   \n",
       "                       LoRA (Individual)         22.8%    23.7%  53.5%  1.14%   \n",
       "                       LoRA (Mixed)              24.1%    22.3%  53.9%  1.97%   \n",
       "                       TaskWeaver (Ours)         24.9%    23.9%  54.5%  1.67%   \n",
       "google/gemma-3-270m-it Base                      18.9%    23.0%  43.5%  4.55%   \n",
       "                       LoRA (Individual)         25.6%    25.0%  56.4%  3.64%   \n",
       "                       LoRA (Mixed)              25.3%    21.3%  52.0%  3.41%   \n",
       "                       TaskWeaver (Ours)         21.1%    23.7%  45.7%  5.84%   \n",
       "Qwen/Qwen3-0.6B        Base                      21.7%    31.7%  63.6%  50.0%   \n",
       "                       LoRA (Individual)         50.7%    71.8%  78.8%  35.9%   \n",
       "                       LoRA (Mixed)              54.4%    68.8%  68.6%  34.5%   \n",
       "                       TaskWeaver (Ours)         35.2%    48.5%  64.1%  52.5%   \n",
       "\n",
       "                                         HELLASWAG OpenBookQA    SNLI  \\\n",
       "Model                  Mode                                             \n",
       "EleutherAI/pythia-70m  Base                  4.94%       8.2%  0.519%   \n",
       "                       LoRA (Individual)     25.4%      22.4%   34.9%   \n",
       "                       LoRA (Mixed)          24.6%      26.6%   31.0%   \n",
       "                       TaskWeaver (Ours)     24.8%      28.6%   29.5%   \n",
       "google/gemma-3-270m-it Base                  24.7%      24.6%   34.3%   \n",
       "                       LoRA (Individual)     24.2%      26.4%   42.9%   \n",
       "                       LoRA (Mixed)          23.5%      25.2%   33.3%   \n",
       "                       TaskWeaver (Ours)     24.5%      27.6%   34.7%   \n",
       "Qwen/Qwen3-0.6B        Base                  25.9%      34.2%   42.4%   \n",
       "                       LoRA (Individual)     50.7%      62.2%   84.2%   \n",
       "                       LoRA (Mixed)          33.0%      53.4%   76.9%   \n",
       "                       TaskWeaver (Ours)     29.0%      38.8%   49.2%   \n",
       "\n",
       "                                         Winogrande (M)  SVAMP CommonSenseQA  \\\n",
       "Model                  Mode                                                    \n",
       "EleutherAI/pythia-70m  Base                       6.08%  2.33%         3.44%   \n",
       "                       LoRA (Individual)          49.7%      -             -   \n",
       "                       LoRA (Mixed)               44.3%   3.0%         18.3%   \n",
       "                       TaskWeaver (Ours)          48.4%   1.0%         19.7%   \n",
       "google/gemma-3-270m-it Base                       50.6%  19.3%         18.4%   \n",
       "                       LoRA (Individual)          53.8%      -             -   \n",
       "                       LoRA (Mixed)               50.9%  4.67%         20.6%   \n",
       "                       TaskWeaver (Ours)          47.8%  16.3%         21.5%   \n",
       "Qwen/Qwen3-0.6B        Base                       50.4%  73.0%         38.2%   \n",
       "                       LoRA (Individual)          48.7%      -             -   \n",
       "                       LoRA (Mixed)               48.5%  52.7%         50.9%   \n",
       "                       TaskWeaver (Ours)          52.1%  74.7%         45.9%   \n",
       "\n",
       "                                         RACE (Middle)  \n",
       "Model                  Mode                             \n",
       "EleutherAI/pythia-70m  Base                      8.64%  \n",
       "                       LoRA (Individual)             -  \n",
       "                       LoRA (Mixed)              18.7%  \n",
       "                       TaskWeaver (Ours)         25.1%  \n",
       "google/gemma-3-270m-it Base                      20.8%  \n",
       "                       LoRA (Individual)             -  \n",
       "                       LoRA (Mixed)              22.8%  \n",
       "                       TaskWeaver (Ours)         23.0%  \n",
       "Qwen/Qwen3-0.6B        Base                      34.4%  \n",
       "                       LoRA (Individual)             -  \n",
       "                       LoRA (Mixed)              64.8%  \n",
       "                       TaskWeaver (Ours)         44.2%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_df = pd.concat([base_scores_df, lora_scores_df, mixed_lora_scores_df, hypernet_scores_df], \n",
    "               keys=['Base', 'LoRA (Individual)', 'LoRA (Mixed)', 'TaskWeaver (Ours)'],\n",
    "               names=['Mode', 'Model']).swaplevel().reindex(models, level=0).fillna('-')\n",
    "\n",
    "display(scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40db3231",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taskweaver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
